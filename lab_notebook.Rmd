---
title: "Lab Notebook"
output: html_notebook
---
#Goals for Feb 5 - 9

- Lit review - 6 papers: III

- Lab meeting

- finish analyzing data & write/send Mike/mSphere memo

- learn github/submit pull request

- figure out parsing text from each xml node

- ~~scrape citations~~
 
#2018/02/08 

**To do**

1. finish prepping for lab meeting

1. analyze transfer data & start memo w/o updated citations

1. continue XML parse

#2018/02/07

**- lab meeting presentation**

+ worked on slide deck, need to add more background data

**- Read Marcy's lab meeting doc**

**- Parse XML**

The XML structure is not very neat. There are duplicate naming schemes that prevent easy dump into a dataframe. Reading up on what [XML files are] (https://www.w3schools.com/xml/default.asp) and how they work to better understand the parsing procedure. 

+ An XML file is built of nodes/elements in a tree-like structure. The root node is the beggining and the end. It is a "parent" to the next subset of nodes, which are in turn a "child" to the preceeding node. Each element can have text (contained between <node>text</node>) and attributes (contained within the element e.g., <node category = root>text<node/>).

+ XML files have a "self-describing" syntax. A prolog defines the XML version and characer encoding. The next line is the root element, the next is a child element of the root, which in turn can have child elements. The child elements from a single "parent" are "siblings". 

+ Tags are the brackets of a node and come in pairs. If there is an opening tag <>, then there is a closing </> tag. <tag /> is also appropriate syntax for an empty node/tag. **Tags are case sensitive!** 

+ XML attribute values must be in quotes. Attribute values can often be stored as elements instead. "metadata (data about data) should be stored as attributes, and the data itself should be stored as elements"

Mapped the EJP/ASM XML structure. Two major branches: manuscript & people. Manuscript contains data split by version: authors, editor, referees (suggested, contacted & accepted), referee decisions, editor decision, etc. where persons are identfied by an ID number. The people branch contains identfying data for each ID number: country, first & middle names, title, & gender

**- Scraping citations**

Having trouble figuring out how to scrape citations, apparently it's harder than I thought b/c nobody (google scholar, etc) wants to make their data scrapable. I'm also not sure how "valuable" this will be in the long run so I'm shelving it, along with the altmetrics scraping, for now. In the meantime, I've emailed Judith and Tyler, informatists at Taubman, to set up a meeting to discuss what resources they have that I can use. 

**- Marc's seminar**

#2018/02/06

**-Scrape citations**

Built a function and for loop to collate doi numbers from every data set into a single file using the magicfor package, next I need to figure out how to batch process doi #s
```{r, eval=FALSE}
source("Code/get_transfer_stats.R")
library(magicfor)

#Generate list of doi for WoS analysis
get_doi_file <- function(input_txt){
  text <- read_tsv(input_txt, col_names = TRUE)
  as.list(text$`CrossRef DOI`)
}  

#list of all journals data sets
transfer_master_list <- as.list(c("Data/aac.txt", "Data/aem.txt", "Data/cvi.txt", "Data/genome_announcements.txt",
                        "Data/iai.txt", "Data/jb.txt", "Data/jcm.txt", "Data/jv.txt", "Data/mBio.txt",
                        "Data/mcb.txt", "Data/msphere1.txt", "Data/msystems.txt"))

#loop reading in of each journal dataset & pull doi's - collate into a single vector using magic_for then write to csv
magic_for() #starts function call

for(i in transfer_master_list) {
  doi_list <- get_doi_file(i)
  put(doi_list)} #indicates what data needs to be pulled

magic_result_as_vector() %>% #collates into vector
  write.csv("transfer_doi_master.csv")
```


**-Work on lab meeting presentation**

Re-read paper and started slide deck. 

**-Lit review**

1. "Threats to objectivity in peer review: The case of gender" Kaatz et al., 2014

***

+ Implict biases against women exist and science is consider more "M" than "F" b/c of stereotypes. These sterotypes subtley shift expectations such that women have to achieve more to be rated equal to men. This despite women recieving praise for equal achievements b/c she exceeded the lower expectations. 

+ Aged 40-65 hold the strongest implicit biases, the same age as reviewers. Is this affecting acceptance rate of F-authored papers and grant proposals? 

+ **"Women are generally found to have fewer but overall higher-quality peer-reviewed scientific publications than men (Symonds, 2006)"** 

+ **"If gender bias operates in grant peer review, one would expect that different evaluative standards for M and F investigators would be exaggerated when assumptions of performance most strongly align with M gender stereotypes; that is, where science and leadership conflate."**

+ "Data from the NIH website show persistently lower Type 2 R01 or R01- equivalent success rates for women versus men, and there was no change after the 2009 change in scoring and critique structure (range, 2-8% lower; average, 5%)"

+ Writen critiques of R01 proposals are significantly different from M to F. Reviewers provide more praise to women for exceeding lower performance expectations while critqiues for M have more negative words --> they recieve similar scores and funding outcomes!

+ Suggested interventions for scientific review:
    + reflect on susceptibility for bias
    + focus and don't rush through a review
    + imagine a female scientific leader
    + review assesment criteria before evaluation
    + challenge evaluation with opposite gender, ethnicity, institution
    + avoid gender-typed terms in review criteria

+ Follow up: 
    + Symonds, et al. "Gender differences in publication output" Plos one (2006); 
    + Pohlhaus et al. "Sex differences in application, success, and funding rates for NIH extramural programs" Acad Med (2011); 
    + Kaatz, et al., "A quantitative linguistic analysis of NIH R01 application critiques from investigators at one institution" Acad Med (2014)
    
***
2. "Journals invite too few women to referee" Lerback & Hanson (2017)

***

+ Peer review is a career building activity that develops writing skills & expertise, + fosters relationships with other scholars. Esp. important for young scientists. Most studies don't have access to gender/age data. 

+ this data set has age and genders of authors & reviewers from 2012 to 2015 for AGU journals (20 journals; 6,000 papers) Find that women were used as reviwers less often than expected - based on proportion of members in that age/gender group. 

+ 1st authored papers are important for career development/hiring/promotions. 1st authors are typically the cooresponding authors. 

+ Women 26% of submitting 1st authors vs 28% members. Acceptance rate higher than for males, gender of editor/reviewer did not affect. Women submitted fewer overall papers than M

+ higher acceptance rates could be due to reverse gender bias or better journals targeting/manuscript preparation

+ Only 20% of reveiwers were women, persistent accross all age groups. F reviwers suggested 21% of time by F authors, 15% by M authors. Women of every age declined more often than men. Main reason given was workload. "The differences may also reflect varying approaches to risk or confidence"

+ **"It [reviewing] provides positive feedback that a scholar is respected and participating in their field and fosters self-confidence, all of which lead to increased retention of woemn in geoscience"**

+ Hiring F editors has helped AGU mitigate teh disparity in recommendations. Encourage authors/editors to invite more women to review, esp younger.


+ Follow up: 
    + Holmes et al., "women in the Geosciences: Pracitcal, positive practices toward parity" (2015)

***
3. "Time-to-credit gender inequities of first-year PhD students in the biological sciences" Feldon et al., (2017)

***

+ Background: Tenured F faculty are expected to take on more mentorship/service, which is uncompensated & undervalued (Hirshfield, 2014). When M & W work equal hours, M percieved as more dedicated & productive. W 50% of biology phd grads, only 30% tenure-track positions. Trouble finding post-docs? Longitudinal studies suggest that # grad papers predicts productivity later in careers.

+ Research questions:
    + Do men and women report different amounts of time spent on supervised research?
    + Are there differential reported influences associated with research time spent for men and women?
    + Is there a differential publication yield for men and women per time spent on supervised research?
    
+ Methods: focus on field with lab-based experiments, multi-level modeling to account for insitutional culture/practices. Time spent on research reported biweekely. Reported # journal articles, conference papers, & published abstracts they recived authorship credit on. 336 students/53 institutions. Completed bi-weekly surveys for time, + 3 year-end surveys. Used hierarchical linear modeling to analyze logitutinal data

+ Results: Men more confident than women in designing experiments & formulating research hypotheses. W report upto 30hr more time in supervised research than M. Found significant gender by total hrs spent on rearch for journal articles. For 100hr spent on research, M 15% more likely to recieve authorship credit. 

+ Discussion: "men spend significantly less time engaging in supervised research, are less likely to attribute their time alloca- tion to the demands of assigned tasks, and are 15% more likely to author published journal articles than their female counter- parts per 100 hours of research time" Gender inequality manifests as early as 1st year of grad school in the "time-to-credit" payoff. F students percieve greater estimate of effort req'd for success (Smith et al., 2013). Disparities in publishing may account for PD hiring discrepancies. "no evidence that lower self-efficacy prompts women to self-select out of professional opportunities in the first years of their doctoral studies", "the relevance of confidence in experimental design skills to time spent on research may point to a greater relevance of those skills in the tasks assigned to male graduate students within the laboratory environment."

+ Follow up:
    + Hirshfield et al., (2014) "She's not good with crying: the effect of gender expectations on graduate students assesments of their principal investigators"
    + Reid (2015) "Embracing, passing, revealing, and the ideal worker image: how people naviage expected and experienced professional identities."
    + Sheltzer & Smith (2014) "Elete male faculty in teh life sciences employ fewer women"
    + Smith et al., (2013) "When trying hard isn't natural: women's belonging with and motivation for male-dominated STEM fields as a function of effor expenditure concerns"

#2018/02/05

**-Transfer stats**

+ Worked more on pulling altmetrics but ran into trouble running a list of dois with a bad doi. I also think I need to get my own altmetrics key so I'm shelving that part of the analysis for now. 

+ Need to figure out how to access updated citation data going to manually pull citation data from WoS, but working twoards generating a script to isolate doi numbers from each dataset to do a single pull and generate a single data set of citation data. Then do a left join for each journals dataset. Problem is that everytime I run a for loop, the doi numbers write over themselves instead of adding to the list. 

**-Read Pat's opinion on reproducibility**

#2018/02/02

**- Transfered articles**

I was able to build a function pulling altmetrics data and determining the "time in transfer" (publication date - rejection date). It worked when applied to mSphere & mSystems data, but all other data sets are failing the altmetrics function. I will have to explore why. Perhaps there are other types of articles like Erratum that need to be filtered out.

Also generated plots where citation metrics are on a log10 scale since the Altmetrics data can get pretty high.
```{r}
source("../Impact_Vizor/Transfers/Code/get_transfer_stats.R")

mSphere <- get_transfer_stats("../Impact_Vizor/Transfers/Data/msphere1.txt")

ggplot(data = mSphere, title= "Stats on Transfers to mSphere") +
  geom_point(mapping = aes(x= log_value, y= `Time in Transfer`, color = `Submitted Journal`)) +
  facet_wrap(~ metric) +
  labs(x= "Citation Value (log10)")
```

**- Obtained journals reports from Melissa**

**- Meet with Zack about microscopy experiment**

**- Internet rabbit hole to pull more papers re: gender in diversity**

#2018/02/01

**- Read Gong, et al. paper for lab meeting**

**- Seminar + lunch w. speaker (Randy Stockbridge)**

**- Lab meeting**

#2018/01/31

**- Cascading articles**

Figured out how to parse the dates with lubridate::mdy & wrote script for filtering out the erratum. Running into a problem with how to apply the script because the document has newlines. If I attempt to remove newlines from the tibble, it converts to a string so I wrote a function to replace newlines then sapply to the "Published Title column". Unfortunately, it still isn't working. Supposedly it can't find that object?
```{r, eval=FALSE}
#function to replace hidden line break characters from text strings
no_breaks <- function(x){
  gsub("[\r\n]" , "", x)
}

#filter out erratum
mBio_no_err <- mBio_raw %>% 
  sapply(no_breaks()) %>% 
  filter(`Published Title` != str_view(string = `Published Title`, pattern = "Erratum"))
```
Looks like stringr returns a string but filter requires a logical output, so used grepl which returns True/False
```{r, eval=FALSE}
filter(grepl("Erratum", `Published Title`) == FALSE) 
```
Wrote a series of scripts to pull and join altmetrics data with clean impact vizor data, unfortunately they don't work with in a function together.
```{r, eval=FALSE}
#write function to pull altmetrics data for each doi & convert to d.f.
get_alt_raw <- function(x){
  altmetrics(doi = x) %>%
    altmetric_data()
}

#function to retrieve altmetrics into clean dataframe
get_alt <- function(input_dataframe){
  doi_list <- list(input_dataframe$doi)#generate list of doi numbers
  alt_score <- input_dataframe %>% pmap_df(doi_list, get_alt_raw) %>% #pull altmetrics
    mutate(Altmetric = score) %>% #obtain column titled "Altmetrics" of data from "score"
    select(doi, Altmetric) #pull relevent data
  joined <- input_dataframe %>% full_join(alt_score, by="doi") #join to original dataset
  return(joined)
}

 "Error: Don't know how to pluck from a closure"
```
After merging altmetrics data, next step is to scrape & merge citation data from WoS

**- Lit Review**

1. "Is there a sex bias in choosing editors?", Dickersin et al., 2003

***

+ Background: People are interested in studying careers of F in science/medicine. 45-60% of those in Public Health:Epidemiology graduate programs are women. F faculty numbers have increased 23% in 1976 to 36% in 1991 but little data following grad school. Study questions: F representation in epi editorial boards vs proportion of F authors/reviewers 1) does prop of F editors reflect F authors/reviewers? 2) Has prop of each changed over time?

+ Methods: Looked from 1982 - 1994 (sp journals in 82, 87, 92 & 94) in 4 journals (AJE, JCE, AE, Epi). Identified editors, reviewers, and authors (down to 8) from articles and volumes, attributed sex where possible. 

+ Results: All F editors in All journals ranged from 6.5% to 16.3%. Removing unassigned gender persons, F were on average 28.7% of authors, 26.7% of reviewers and 12.8% of editors. Values ranged from year to year

+ Comment: The proportion of F editors is low, though it had increased over time & in newer journals. Possible that women just aren't as good at epi as men? Not if you look at productivity via papers & asking to be reviewers. Cohort effect - recent influx of women means ineligible at higher proportion than eligible but prop of F editors didn't increase over time after incrase in F authors nor does it seem that more F editors have been added. Women may be refusing membership on boards or less likely to nominate themselves. Selection bias by male EiCs. **increased "professional influence" is conferred by being an author, reviewer, or editor and that each of these roles has progres- sively more influence in the scientific community.**

***

2. "Is there gender bias in JAMA's peer review process?", Gilbert et al., 1994

***

+ Background: PUblication bias occurs in 3 stages: gender bias in differential handling of manuscripts is one. 

+ Question: the gender ofthe corresponding author, the assigned editor, or the reviewers had an effect on, or association with, the peer review, manuscript processing, or acceptance rates of research articles submitted

+ Methods: pulled data from 1991 including corresponding author, assigned editor/reviewer, reviewer recommendations, turnaround times for review, editor ratings of reviewer, final decision. Genders determined. 

+ Results: Editors employed most M full-time, most F part-time but handeled 2x #manuscripts. F editors assigned 30% more F authored papers than men. M reviewers assisted M editors more often than F. F reviewers aided equally. F editors rated reviewers lower than M ed, irrespective of gender. M reviewers took ~2 days longer to return reviews. M authored manuscripts fared worse in initial review by editor, F ed summarily rejected at higher rates than M (b/c higher case load?). No sig diff following review or in overall tally.

+ Comment: "the evidence suggests that either female editors are assigned manuscripts of lower quality, irrespective of the corresponding author's gender, or female editors' higher rejection rates without other review shows a differenee in the level of criticism between male and female editors" OR they are triaging a higher case load to a managable number of papers

#2018/01/30  

**- cascading articles memo**

Found a package to use doi to pull altmetrics data to add. Pretty cool, but along the way realized that some of the "publications" listed in the dataset are actually erratum so I need to filter those from the list prior to processing. 
```{r, eval=FALSE}
library(rAltmetric)
get_alt <- function(x){
  altmetrics(doi = x) %>%
    altmetric_data()
}
dummy_doi <- list("10.1128/mbio.00590-17", "10.1128/mbio.00713-17")
raw_alt <- lapply(dummy_doi, get_alt)
```

**- parsing XML files**

Worked on parsing more data from XML files. Was able to pull doi, first author id, editor id, and submission date into a tibble. Also want to pull out corresponding author, final decision date, reviewer ids & decisions. Found that the bottom of the file links person ids to first names, country of origin, and sometimes gender. Need to figure out how to parse that data out also. One issue is that a "reject & resubmit" decision results in a new submission/xml file -> how do you link data? Is the "key" constant? Or the manuscript number? - latter seems unlikely since that is also how the xml file is titled

**- ASM all staff meeting**

**- Gender in publishing**

* Additional questions: 
    + Are women editors assigned to diff # of papers?
    + Do women editors/reviewers have an associated cost in reduced publications
    + Do women accept/reject female authors more/less than men - vice versa

**- Lit review cont:**

1. "Male gatekeepers gender bias in the publishing process", Bransch & Kvasnicka, 2017.

***
  + Background: Editors can also take more indirect influence, e.g. by selectively assigning submissions to reviewers who favor certain subjects or do a better job at reviewing (which improves manuscript quality), or by influencing the decisions of other editors in board meetings or informal talks (Addis and Villa, 2003). Gender bias may also entail significant efficiency losses. Few studies have looked at editorial boards, mostly for professional ties, not gender differences. Presence of women on hiring committees have negative impact for female candidates. Two types of literature re: female under-representation in economics: 1) Demand-side---potential discrimination by employers e.g., universities & research institutions---studies suggest statistical discrimination b/c unobservable productivity &/or decision-makers aversion to interact w. women 2) Supply-side--M/F productivity gaps e.g., lack of professional networks & mentors for women, < likely to apply for promotions, less competition, > time on socially desirable tasks that don't count towards tenure
  
  + Methods: Pulled data from the article, editorial info from each issue, citation info from WoS. Assigned gender to authors by hand -> 1 if any F author/0 if none. Assigning editors to papers was difficult: 1st had to learn class of editors responsible for handling & decisions. 2nd editors listed in issue may be different from those who handeled the articles in that issue. Chose to consider the avg share of F editors of a journal over the 3 yrs before an article was published ('editor share'). Used article citation as a proxy for article quality. Used JEL codes to bin articles by field to account for citation. Attempted to control for # of authors, # of pages, and year of publication.
  
  + Results: only 16.3% of articles had at least 1 F author. As the share of F editors increased, share of F-authored articles decreased. Quality increased with > F editor share (up to 11.7%), but then declined (based on citation count). Possible reasons include:
    + F editors may discriminate to protect their standing (Broder, 1993)
    + M editors may discriminate less in all-male environment (Akerlof & Kranton, 2000)
    + "Queen Bee syndrome" F editors prefer M b/c acclamated to M-dominated system (Ellemers et al., 2004)
    + Editor responsiblities reduce time for research & publications (Vernos, 2013)
    + F authors submit less to journals w. F editors
    + Gendered networks (Saloner, 1985) - M networks may be disrupted, at first improving quality, then be replaced by F networks
    + F may initially improve performance of group (Wooley et al., 2010), then productivity effect is reversed

***

2. "To name or not to name: The effect of changing author gender on peer review", Borsuk et al., 2009

***
  + Background: M reviewers tend to recommend accept/reject, F revisions (Davo et al., 2003). # of authors/nationality can bias. Gender has also been shown to have an effect, but trends may be changing. Both editor & reviewer populations are mostly male. Reviewer performance varies by gender. 
  
  + Methods: Used published paper w. journal's mean citation #, formated as manuscript w. M/F/I/NN, & distributed to UG/Grad/PD/faculty. Only 2 faculty responded.
  
  + Results: UG in class more likely to reject & give lower quality rating than online. Author gender had no effect. PD/Grad more likely to reject than UG. F rated manuscripts lower than M, primarily b/c F PD. 

***

3. "Why are women underused in the JECH peer review process?", Davo et al., 2003

***

+ Background: emperical evidence about sex bias in choosing referees w. out justification by any qualitiy criteria

+ Methods: Year 2000 JECH databased mined retrospectively for peer review management info. 31% F reviewers, took 1st 100 M & 100 F reviewers for convenience then looked at ALL reviews provided by these reviewers (from 1992-2002, 48% female). Variables: Sex (independent), time to answer, editors percieved quality, reviewer recommend decisions.

+ Results: All women answered w. comments, 6.5% of men did not. No differences re: time to answer or editors percieved quality. Women 3% more likely to ask for major revision, Men 4% more likely to accept or reject.

+ Discussion: Bias - manuscripts may be assigned differently 

+ Follow up: Gilbert et al., 1994; Dickersin et. al, 1998
  
#2018/01/29

**- ASM memo re: cascading articles**

If available, I pulled data of papers rejected from ASM journals that were published in OTHER ASM journals (i.e., excluded mSphere from submissions, then looked at papers published in mSphere). Goal is to look at citation/Mendeley save rates, which journal is publishing rejects from which journal, and look at average times from rejection in A to publication in B. Had to import files as tab delimited. Having trouble parsing the date format. 

**- Emilio Bruna, UF "What 1.25 million papers tell us about global biases in the creation & diffusion of scientific knowledge"**

+ Who are we & where do we work - as ecologists 

+ all articles with tropical field sites = 56% of studies conducted in 1 of 7 countries (brazil, costa rica, mexico, puerto rico, Australia)

+ 20 countries represented by only 1 pub (in biotropica)

+ 62% had lead author based outside of country in which research was conducted (U.S. 34% & Brazil 11%)

+ "ecology is the art of proving the obvious with increasingly advanced statistics" 

+ 45% of all authors are foreign scentists, 28% in country sci, 27% multinational teams

+ Working collaborative w. local scientsits/ communitites is the right thing to do!

+ 1) better understand the social/political/economic context in which one's research is embedded 2) minimize "intellectuall export" 3) Ethical professional conduct

+ Henry  Wickham - late 1800's took hundreds of seeds of rubber trees, grow seedlings and undercut the brazilian market on rubber (biopiracy)

+ Personally/professionally rewarding: 1) professional skills 2) professional recongnition 3) unique outreach 4) Fun 

+ international work comes at a cost: time/money/stress (= productivity)

+ What is the impact of your scholarship?

+ Do the national affiliations of authors influence journal placement & citation performance? 1.25 million articles, broad topics

+ 1) journal placement impact factor & IF quantiles

+ 2) citation performance total citations of a paper published in a given year in a given journal (it's all relative!!) & citation quantiles

+ caveats: citations are only one way to quantify "impact", I think IF are used incorrectly so often they're effectively useless

+ 1) identify country of author's listed institution 2) journal impact factor 3) # of citations

+ different from previous work b/c of how authorship is grouped

+ 2 approaches: what impacts citations? # authors, # countries, # references, Journal, Age

+ differences in distribution of data points (papers) for each value of covariate (co author country combos) = separate coefficitens (slopes) for each, in the past people have looked at combos but not independent

+ international collaboration has a strong & positive effect on article performance (articles published in journals w. higher IF & articles have more citations relative to others in same journal x year) - above & beyond # of coauthors

+ Why: 1) multinational authorship - reflects global scope 2) global authors = greater visibility (non-overlaping networks) 3) more countries = more research funding 4) Maybe the work is just better -> **diversity promotes hard work & creativity before any interpersonal interactions even take place**

+ more preparation b/c less comfortable - less knowledge about people & backgrounds must be more prepared to work effectively 

+ national identity matters (+ or -) - in re: to both impact factors & citation rates

+ Why are papers by Brazilian authors "underperforming" at the journal level & "overperforming" at the citation level: Journal placement (1, negative bias at the peer-review stage 2) biased author effect, Akre, 2011) + Citation performance (better science, citation bias) -> bias in 3/4 options

+ Review stage bias - Crane, 1967 "Gatekeepers of science" - powerful -> small, elite group provides stamp of approval: shape direction of field, shape direction of field, choose new editors, confer legitimacy -> follows workplace dynamics - like recruits like

+ Gatekeeper project

+ Editorial boards should be aspirational, not "reflective"

+ Has the richness & diversity of the editorial community changed over the last 3 decades? Yes, richness has increased, but editorial boards have increased at the same time -> looking at diversity, however, it has remained flat & low. 55% in U.S., 12% in U.K.

+ Institutional diversity of editorial boards: (1985 - 2015) >75% are at research schools like U.M.; 36% gov't; 25% NGO --> nobody from community or tribal colleges

+ Takehome messages: 1) internationall collaboration (& funding) gives a high return on investment 2) Implicit biases may influence how research is judged druing evaluation & citation 3) Biases in the production, diffusion & evaluation of scholarship can be overcome, but it requires planning, effort, & accountability 4) Biases in the production & diffusion of knowledge have socio-econoimc consequences 

+ "95% of the new science in the world is created in the countries comprising only 1/5 of the world's population. And much of that science -- in the realm of health, for example -- neglects the problems that afflict most of the world's people. This unbalanced distribution of scientific activity generates serious problems not only for the scientific community in the developing countries, but for development itself. It accellerates the disparity between advanced and developing countries, creating social & economic difficulties at both national & international levels" - Kofi Annan (2003) Science

+ **Scientific productivity, doesn't matter the topic, leads to socioeconoimc development**. Knowledge is power

+ Mapping scientific collaborations - next project: 1) Scientific productivity in Latin America 2) Structure of scientific collaborations

**- Lit review cont:**

1. "Author's gender affects rating of academic articles: Evidence from an incentivized, deception-free laboratory experiment", Krawcxyk & Smyk,  2016.

  ***
  + Background: describes gender-science sterotype; age as a factor of perception (younger > odds of drawing woman sci; young women more likely to be sterotyped); unconscious correlation betwn gender & qualification; women held to higher standard, often judged by males, at risk of skewed persepective of skills; career stage may make a difference in gendered evaluations; 2009 study found no differences in reviews of article written by M/F/GN - female  postdocs most critical;  2013 study found that male-authored abstracts rated higher on average (but completed a questionanaire about opinon on gender  roles??)
  
  + Methods: 1) told subjects the task (no deception); 2) provided entire paper; 3) financial reward for correctly answering a relevant question; 4) no internet; 5) asked question about paper elements to learn if "traditionally feminine" vs "masculine" aspects were judged differently; Used 5 pairs of papers written by mixed-gender authors from top schools; pilot study w. 4 students who read and rated all 10 papers similarly; Each study subject read and evaluated one paper described as "male/female/young male/young female economist" - no names to exclude effect of nationality/ethnicity; all subjects in a single session recieved the same paper with the same assigned gender; pilot study was repeated without gender/publication data
  
  + Predictions: 1) female authors will recive lower ratings than GN/M & be less often judged as published 2) Young female will be judged inferior to female
  
  + Results: publication prediction accuracy was essentially random; male-authored papers more likely to be considered "published"; percevied age had no effect; 
  
  + Discussion/conclusion: gender, but not age, of author matters during evaluation; self-selected subjects interested in economics (likely future academics); research conducted at U of Warsaw - 50-60% F PhD candidates/ 20% F full-time professors; subjects approaching age of early career decisions, bias against women suggests women fail to see successful F scholars & may alter decisions accordingly; 
  
  + Follow up: Albrecht et al. (2013); Ruben et al. (2014); Wenneras and Wold (2001); Tregenza, 2002; Link, 2998; Ceci and Williams (2011);   Moss-Racusin et al. (2012); Williams and Ceci (2015); Paludie and Bauer (1983); Paludi and Strayer (1985); Peck, 1978; Borsuk et al. (2009);  Knobloch-Westerwick et al. (2013)

**-Parsed XML file** 

Used xml2 package, was able to identify specific content, (_e.g._, country, author id):
```{r}
library(xml2)
xmldoc1 <- read_xml("XML/Files/AEM00003-14.xml")
xml_text(xml_find_all(xmldoc1, "//country"))
```
I can also generate a list of the author ids for further analysis:
```{r, eval=FALSE}
author_id <- as.list(xml_text(xml_find_all(xmldoc1, "//author-person-id")))
```

#2018/01/26

**- set up digital notebook using Rmarkdown notebook**

**- lit review cont:** 

1. "Causes for the persistence of Impact Factor mania", 2014; 

1. "Sharing of science is most likely among male scientists", 2017; 

1. "Males are over-represented among life science researchers committing scientific misconduct", 2013

**- Parsing XML files**

Successfully imported xml file and pulled the rootnode.Still having trouble pulling data (eg, country, referee-recommendation) from the node. Tried using "xml2" package which I can get to obtain a count of the nodes, or return text from the entire file, but not return the text from a single node.

**- Figure outline for "gender in publishing"**

1. gender of all editors over time

1. breakdown into editor type: e.g., EiC, senior, associate

1. gender of all reviewers over time

1. gender of all senior authors over time

1. gender of all first authors over time

1. proportion of gender at each stage: e.g., author, reviewer, editor by type

1. proportion of recruitment by gender, i.e. does eic gender impact editor gender; does editor impact reviewer gender 

Would also like to explore the effects of gender on review status - may be better as a second paper "gender in review"

1. evaluate and score reviewer comments for theme - trends based on author gender and/or reviewer gender

1. evaluate time from submission to final decision (focus on time spent in editor hands/not authors) - trends based on author/reviewer/editor gender

1. breakdown above based on number of rounds of review

1. does final decision differ by author/reviewer/editor gender

All of these questions could also be applied to geography
