---
title: "Lab Notebook: July 2018"
output: html_notebook
---
#Goals: July 30 - August 3
1. Authorship paper:
    + Draft intro
    + Genderize scale up & merge
    + Link manuscripts
    + Start to analyze data

1. Monthly journals report: Get eJP access
    + Arrange first XML pull
    + Write script to pull data needed for monthly report (deencrypt, then re-encrypt files)
    + Verify protection of PPI  
    + Write SFTP protocol

1. ASM blog post
    + Research/outline pathogenic fungi post
    
1. Read/edit Marc's paper
    
#2018/07/31

**- Authorship paper**

Work on script to merge genderized names with the people df. Order is join by: country & first name, first name, middle name & country, middle name. About 20% of the names weren't assigned a gender. Cleaned up script & wrote pbs script to run on flux (tomorrow?).

The script to link manuscripts is still running (ugh).

**- ASM blog post**

Revise Microbial Myths post. 

#2018/07/30

**- ASM blog post**

Pull reviews/articles about pathogenic fungi (plant & humans) & work on outline.

**- Authorship paper**

Worked on linking the XML files. Ended up needing 5 joins to ensure that the manuscripts were all matched & had to submit job to flux b/c the matching script is going to take too long.

**- Monthly Journal Report**

How do I get access to an encrypted network? Is that necessary?

What encryption software does Flux currently have installed?

https://www.howtoforge.com/tutorial/linux-commandline-encryption-tools/

https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server

Worked on script to parse xml files - need to know names of requested fields.

Set up public/private keys to automate transfers (prevents password entries)

I bet Pat has a script for this??

#Goals: July 23 - 27
1. XML parse: 
    + ~~Scale up to AEM XML files on flux~~
    + ~~Scale up to all files~~
    + ~~Genderize scale up~~ & merge
    
2. Authorship paper 
    + ~~Research & outline for chalk talk:~~
        + Intro
        + Materials & Methods
        + Results
        + Discussion

3. Monthly journals report:
    + ~~Give Joel list of missing data~~

4. ASM blog post
    + ~~write Microbial Myths video description~~

#2018/07/26

**- Lab meeting chalk talk**

Going to have to be careful with de-identification of data prior to making it publically available.

Check genderize.io against Nichole's dataset?

Publish at ASM for the audience & reach

**- Authorship paper**

Work on outline for intro & results.

**- Genderize scale up**

Cleaned up initials & whitespaces in names & so far the gender_by_country assignment is working without errors! But... it did worse than 50% assignment

Started working on script to merge genderize results with people df. Have to decide what I want to do with Joel's predictions: completely discard or compare?

**- XML scale up COMPLETE!!**

Yay! I have all the data now! (until we get more from eJP anyway)

#2018/07/25

**- BA manuscript revisions**

**- genderize.io scale up**

Tested out genderize script with list of 28,000+ names from the AEM dataset. The country code list is so restrictive that I'm starting to question the algorithm.

Running into problems submitting names without a country code, I'm getting errors that cancel the whol submission. Tried looping through each name as an individual submission... so far so good...

Issues with genderize:

  - keep getting 502 (server) & 400 (client) errors - might need to better coerce the name entries (no spaces)
  - bias in country codes (only 50% of current list worked)
  - possible to get last names, self-report gender, & email from Microbe attendees or ASM membership lists?
  - Nichole Broderick's dataset?
  - it seems that some country codes on their list don't work (e.g. ireland)

**- XML scale up**

Tried to re-extract people data from all AEM xmls & AEM01261-14 errored
```
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 13, 12
```
The problem here was that not all people had address tags, so by scraping all of the person nodes into a df at the same time I think I can avoid these issues. Scaling up to all AEM files was successfull.

Had to resubmit batch script b/c 400 hrs (requested) is longer than the time until the next scheduled maintananec, so it wouldn't run. Requested 4 hours instead. Script ran but terminated.
```
[1] "starting AAC01551-15"
Error in check_valid_names(tbl_vars(y)) :
  Column `4` cannot have NA as name
Calls: map_df ... left_join -> left_join.tbl_df -> check_valid_names -> .Call
```
Transferred that file locally to check for issues, but when I did everything worked. I think my fix for the address tags solved the issue here.

Successfully got all people data!!!! Job ended before it was done with the manu & review data, but it made it through MCB so I'm pretty sure it will make it through all when I re-submitted the job.

**- Journal club paper**

**- Prep for chalk talk**

#2018/07/24

**- Monthly report**

Send Joel list of needed data.

**- BA paper**

Recieved rejection from mBio. Talked to Phil, we are probably going to revise & submit to mSphere. After talking to Nick though, I think an appeal to the editor might be worth a shot.

**- ASM blog post**

Work on video description for Microbial Myths & send to Ray for feedback.

**- XML scale up**

Successfully scaled the XML parse up to all of the AEM files!!

Submit batch script to scale up to all files!

#2018/07/23

**- Review BA heme paper**

**- XML scale up**

Well, shit. It seems that my method of pulling an entire df using `xmlSApply(input_xmltop[[2]], function(x) xmlSApply(x, xmlValue))` doesn't work b/c the way the files are listed aren't always consistent. Looks like I'm going to have manually use the `get_column` function for every desired data input.

Got manu_parse to work on 500 XML scale up. Running into problems with people_parse now. Can't consistently find "people" in the same location in all XML files. The `get_column` function works, except with multiple address entries, probably the easiest route to fix? `head(n=1)`

**- ASM blog post**

Finished draft & sent to Julie along with selected images. 

Start video descriptive for Ray.

Edit Monika's blog post on plastic digesting microbes.

#Goals: July 16 - 20
1. XML parse: 
    + Scale up to AEM XML files on flux
    + ~~check out script automating genderize.io~~
    
2. Authorship paper - research & outline:
    + Intro
    + Materials & Methods

3. Monthly journals report:
    + ~~Check in with Joel again~~
    + ~~Outline graphs/plots~~
    + ~~Call Joel @ 301-254-5900 on Wed @ 1pm~~

4. ASM blog post
    + ~~finalize draft of Microbial Myths~~
    + ~~submit to Julie~~
    + write video description

#2018/07/19

**- Lab meeting**

**- Read Will's paper**

**- Scale up XML parse**

Troubleshooting tips from Nick. Save alias in `.bashrc` files

AEM XML files are only 1.4G in total, going to download all of them to a local directory to make it easier to work with.   + Linux command: `scp -r akhagan@flux-xfer.arc-ts.umich.edu:/nfs/turbo/schloss-lab/akhagan/ASM_XML_parsing/gender_data/data/AEM ~/Desktop`

**- Authorship paper**

Finsished importing zotero citations/pdfs. Can export citations using the bibtex format.

#2018/07/18

**- Call with Joel about eJP access**

System has 120 reports, don't want to reinvent the wheel. Melissa has the option to set up a batch job. 

Interested in seeing what kind of reports we design. 

eJP primarily in Perl code. Hire interns to teach coding.

Possible to get weekly access to XML. FTP server login & password, or FTP account that eJP would transfer file to. Make sure to use SFTP so that it can be encrypted during data transfer. Data privacy is becoming an issue - requires agreement. Lots at stake for data breach (names, addresses, IP addresses) Need to look into security stuff for computers (GDPR read up).

Linux command line (get a book) - type FTP prompt with web address to access files (eventually type bash shell script to automate). 

The file at rest should also be encrypted. Linux should have encrypt/decrypt commands. Suggests G (will email). Unencrypt for R script, then reencrypt & preferably delete. 

Gender study - AGU study Brooks/Hanson mathematical analysis, to do the study correctly, you need to know the peoples age b/c of bias in older vs younger. Controlling for age was important in checking for bias. Cross-ref against membership group for age data. Could get that from ASM, but there isn't a "universal" unique identifier. Might use last name & email. 

Self-report gender/race/ethincity isn't currently collected. Check membership system. 

Action items:
    + Need to know what fields need to be added to the XML files: full editor names (full all names if cross-ref to membership data), reviewer score, usage stats (web views, pdf views/downloads, unique users), identify transfers and origin, 
    
    + Need to talk about security/encryption of the XML files & access - study up on GDPR
    
    + Check out AGU study (worked with eJP to access data?)
    
    + Linux book
    
Follow up question for Joel:
    + What XML files will be included in FTP batch? All of them? From a given timespan? Those with recent modifications?

**- Microbial Myths**

Watched video & made suggestions. 

Revised draft of blog post & found images.

**- Authorship paper**

Transferred papers for Zotero from my personal computer.

#2018/07/17

**- Authorship Paper**

Started Rmd file, imported Zotero bibliography, started `.bib` and `.csl` files.

**- Flux scale up**

Having trouble with the `parse_manu` function in the scale up. So I decided to write a function that randomly samples and parses XML files then returns a success/error message along with the file name so I can trouble shoot. So far it isn't working... However, it won't actually handle the errors, and the `case_when` returns a random number of identical results. 

#2018/07/16

**- Journals report**

Emailed Joel about eJP access again. Emailed Adar to ask about a login to the eJP site.

Draft outline of reports. 

Joel said to call whenever works. 

**- Genderize.io script**

Finished script, fixed conversion from html special characters to text. Will still have to revisit to: 
  
  1. Double check that all entered names are being queried
  2. Figure out why I'm getting `400` errors

#Goals: July 9 -13
1. EiC stats
    + Editor data for JCM & AEM - scale up to all journals?
    + Top competitors for all journals

1. XML parse: 
    + Scale up to AEM XML files on flux
    + finish script to automate genderize.io
    + ~~test Pat's API key - 438d7ff7f5df44619feace2a7bd07503~~
  
1. Estimated IF
    + ~~Emailed Tyler about WoS API - waiting for Clarviate response~~
    + Get AMR API key from Pat
    + Find/write AMR API request script
    + Test API script on 5 doi's
    
1. Monthly journals report - got parameters from Melissa
    + Identify graphs/plots
    + Identify data needed
    + Check in with Joel again

1. ASM blog post
    + finish first draft of Microbial Myths
    + submit to Julie
    
1. Summer Strategic Goals
    + ~~Finish planning goals~~
    + ~~Meet with Pat~~
    
#2018/07/12

**- Journal Club paper**

**- Lab meeting**

**- ASM blog post**

#2018/07/11

**- estimated JIF**

Work on finding WoS API script for R. Can only find `wosr` which interfaces with InCite & WoS Web Services lite. Can't find one for the AMR api yet. Might have to build this interface from scratch. 

**- ASM blog post**

**- Summer strategic goals**

Sick, email goals to Pat. 

#2018/07/10

**- work on genderize.io script**

Automated it to skip errors & repeat N/A names without a country code. 

Need to find a way to deal with the special characters again.

**- Work on summer strategic goals**

**- ASM blog post**

Work on Microbial Myths post.

#2018/07/09

**- ASM blog post**

Worked on research about bathing infants and the microbiome.

**- Set up new laptop**

Installed gitcola, R, R studio, slack, etc. Cloned github repositories. Also installed a couple of productivity tools: a notepad & task/timer app

**- emailed with Tyler about WoS API**

He sent links to documentation about the APIs & is going to check on which one we subscribe to. I think Pat was using the AMR, I asked him for the API key.